{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SumaiyaZohaRODELA/FAISS-and-CLIP/blob/main/clipp_faiss.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iv93uKEfq3lV",
        "outputId": "378f0141-cb46-419f-ad58-7c4a2de2b388"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.52.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.33.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.2.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.5)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.6.15)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement faiss-gpu (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for faiss-gpu\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'faiss'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2-1088523189.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mfaiss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msentence_transformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'faiss'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "!pip install sentence-transformers\n",
        "!pip install faiss-gpu\n",
        "\n",
        "import os\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import faiss\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import matplotlib.pyplot as plt\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O data.zip https://drive.usercontent.google.com/download?id=1q3dpti5aX4LdD3Mq7bZ4rjTeZbQEljiy&export=download&authuser=0\n",
        "!unzip \"data.zip\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjwzrr4hrSX9",
        "outputId": "6d771f01-7ea2-40bb-ce12-35cb78cecdbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-26 07:34:17--  https://drive.usercontent.google.com/download?id=1q3dpti5aX4LdD3Mq7bZ4rjTeZbQEljiy\n",
            "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 142.250.141.132, 2607:f8b0:4023:c0b::84\n",
            "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|142.250.141.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2545027 (2.4M) [application/octet-stream]\n",
            "Saving to: ‘data.zip’\n",
            "\n",
            "data.zip            100%[===================>]   2.43M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-06-26 07:34:20 (17.8 MB/s) - ‘data.zip’ saved [2545027/2545027]\n",
            "\n",
            "Archive:  data.zip\n",
            "replace image_dataset/pexels-polina-tankilevitch-3735147.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_folder = '/content/image_dataset'\n",
        "\n",
        "# Get a list of all image files in the folder\n",
        "image_files = glob(os.path.join(image_folder, '*.jpg'))\n",
        "\n",
        "# Randomly select 10 image files\n",
        "random.seed(42)\n",
        "selected_images = random.sample(image_files, 10)\n",
        "\n",
        "# Display the selected images\n",
        "plt.figure(figsize=(20, 10))\n",
        "for i, image_path in enumerate(selected_images):\n",
        "    img = Image.open(image_path)\n",
        "    plt.subplot(2, 5, i + 1)\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MOoM8Ux3ryJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_clip_embeddings(images_path, model):\n",
        "\n",
        "    image_paths = glob(os.path.join(images_path, '**/*.jpg'), recursive=True)\n",
        "\n",
        "    embeddings = []\n",
        "    for img_path in image_paths:\n",
        "        image = Image.open(img_path)\n",
        "        embedding = model.encode(image)\n",
        "        embeddings.append(embedding)\n",
        "\n",
        "    return embeddings, image_paths\n",
        "\n",
        "\n",
        "\n",
        "IMAGES_PATH = '/content/image_dataset'\n",
        "model = SentenceTransformer('clip-ViT-B-32')\n",
        "embeddings, image_paths = generate_clip_embeddings(IMAGES_PATH, model)"
      ],
      "metadata": {
        "id": "03Ld0XFgsVAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_faiss_index(embeddings, image_paths, output_path):\n",
        "\n",
        "    dimension = len(embeddings[0])\n",
        "    index = faiss.IndexFlatIP(dimension)\n",
        "    index = faiss.IndexIDMap(index)\n",
        "\n",
        "    vectors = np.array(embeddings).astype(np.float32)\n",
        "\n",
        "    # Add vectors to the index with IDs\n",
        "    index.add_with_ids(vectors, np.array(range(len(embeddings))))\n",
        "\n",
        "    # Save the index\n",
        "    faiss.write_index(index, output_path)\n",
        "    print(f\"Index created and saved to {output_path}\")\n",
        "\n",
        "    # Save image paths\n",
        "    with open(output_path + '.paths', 'w') as f:\n",
        "        for img_path in image_paths:\n",
        "            f.write(img_path + '\\n')\n",
        "\n",
        "    return index\n",
        "\n",
        "\n",
        "OUTPUT_INDEX_PATH = \"/content/vector.index\"\n",
        "index = create_faiss_index(embeddings, image_paths, OUTPUT_INDEX_PATH)"
      ],
      "metadata": {
        "id": "WOQfQR9Ws2E-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_faiss_index(index_path):\n",
        "    index = faiss.read_index(index_path)\n",
        "    with open(index_path + '.paths', 'r') as f:\n",
        "        image_paths = [line.strip() for line in f]\n",
        "    print(f\"Index loaded from {index_path}\")\n",
        "    return index, image_paths\n",
        "\n",
        "index, image_paths = load_faiss_index(OUTPUT_INDEX_PATH)"
      ],
      "metadata": {
        "id": "MV8djPlss6jo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_similar_images(query, model, index, image_paths, top_k=3):\n",
        "\n",
        "    if query.endswith(('.png', '.jpg', '.jpeg', '.tiff', '.bmp', '.gif')):\n",
        "        query = Image.open(query)\n",
        "\n",
        "    query_features = model.encode(query)\n",
        "    query_features = query_features.astype(np.float32).reshape(1, -1)\n",
        "\n",
        "    distances, indices = index.search(query_features, top_k)\n",
        "\n",
        "    retrieved_images = [image_paths[int(idx)] for idx in indices[0]]\n",
        "\n",
        "    return query, retrieved_images"
      ],
      "metadata": {
        "id": "prg7rf5Ks8Bs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_results(query, retrieved_images):\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    # If image query\n",
        "    if isinstance(query, Image.Image):\n",
        "        plt.subplot(1, len(retrieved_images) + 1, 1)\n",
        "        plt.imshow(query)\n",
        "        plt.title(\"Query Image\")\n",
        "        plt.axis('off')\n",
        "        start_idx = 2\n",
        "\n",
        "    # If text query\n",
        "    else:\n",
        "        plt.subplot(1, len(retrieved_images) + 1, 1)\n",
        "        plt.text(0.5, 0.5, f\"Query:\\n\\n '{query}'\", fontsize=16, ha='center', va='center')\n",
        "        plt.axis('off')\n",
        "        start_idx = 2\n",
        "\n",
        "    # Display images\n",
        "    for i, img_path in enumerate(retrieved_images):\n",
        "\n",
        "        plt.subplot(1, len(retrieved_images) + 1, i + start_idx)\n",
        "        plt.imshow(Image.open(img_path))\n",
        "        plt.title(f\"Match {i + 1}\")\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "f1vHvDjos_uj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = 'a ball'\n",
        "query, retrieved_images = retrieve_similar_images(query, model, index, image_paths, top_k=3)\n",
        "visualize_results(query, retrieved_images)\n"
      ],
      "metadata": {
        "id": "OqKrbnfZtD5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example with text query\n",
        "query = 'animal'\n",
        "query, retrieved_images = retrieve_similar_images(query, model, index, image_paths, top_k=3)\n",
        "visualize_results(query, retrieved_images)"
      ],
      "metadata": {
        "id": "8j1mLg-3tMQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = '/content/image_dataset/pexels-w-w-299285-889839.jpg'\n",
        "query, retrieved_images = retrieve_similar_images(query, model, index, image_paths, top_k=3)\n",
        "visualize_results(query, retrieved_images)"
      ],
      "metadata": {
        "id": "VICE9it3tNAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_category(image_path):\n",
        "    \"\"\"\n",
        "    Extract the category from the image path.\n",
        "    Assumes categories are defined as part of the file name before a delimiter (e.g., \"category-filename.jpg\").\n",
        "    Modify this logic if your dataset uses folders or a different naming convention.\n",
        "    \"\"\"\n",
        "    return os.path.basename(image_path).split('-')[0]  # Example: \"pexels-cat.jpg\" -> \"pexels\"\n"
      ],
      "metadata": {
        "id": "tpaSR7UQtTL1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}